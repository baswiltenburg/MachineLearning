{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set-up for training a U-net convolutional neural network for sementic segmentation ###\n",
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(str(Path.home())+'/bomenspotter/notebooks/Bas/Scripts')\n",
    "from DataPreprocessing import *\n",
    "from DataCreation import *\n",
    "import CreateResults as cr\n",
    "from Unet import unet, unet_multiclass\n",
    "from random import sample\n",
    "from owslib.wms import WebMapService\n",
    "import tensorflow\n",
    "from rasterio.plot import reshape_as_raster, reshape_as_image\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import backend as keras\n",
    "work_directory = str(Path.home())+\"/bomenspotter\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set variables and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (256, 256) \n",
    "cell_size = 0.25 \n",
    "epsg = 28992   \n",
    "wms = WebMapService('https://geodata.nationaalgeoregister.nl/luchtfoto/rgb/wms?&request=GetCapabilities&service=WMS')\n",
    "#wms = WebMapService('https://geodata.nationaalgeoregister.nl/luchtfoto/infrarood/wms?&request=GetCapabilities&service=WMS')\n",
    "\n",
    "path_training_data = work_directory + \"/data/n2000_project/training_images/gras_manueel_ahn/training_corrected\"\n",
    "path_mask_data_binair = work_directory+ \"/data/n2000_project/training_images/gras_manueel_ahn/binary_mask\"\n",
    "path_mask_data = work_directory + \"/data/n2000_project/training_images/gras_manueel_ahn/mask\"\n",
    "path_cir_data = work_directory + \"/data/n2000_project/training_images/gras_manueel_ahn/training_cir\"\n",
    "path_rgb_data = work_directory + \"/data/n2000_project/training_images/gras_manueel_ahn/training_rgb\"\n",
    "folder_checkpoints = work_directory\n",
    "\n",
    "# Create N2000_Data object\n",
    "dc = N2000_Data(wms = wms, image_size = image_size, cell_size = cell_size, epsg = epsg)\n",
    "\n",
    "wms2 = WebMapService('https://geodata.nationaalgeoregister.nl/luchtfoto/infrarood/wms?&request=GetCapabilities&service=WMS')\n",
    "dc2 = N2000_Data(wms = wms2, image_size = image_size, cell_size = cell_size, epsg = epsg)\n",
    "\n",
    "# Create N2000_DataPreparation object\n",
    "dp = N2000_DataPreparation(image_size = image_size, path_training_data = path_training_data, path_mask_data = path_mask_data_binair, path_original_data = path_rgb_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data aquisition\n",
    "- Download aerial images based on known polygons\n",
    "- Create raster masks (binary and non-binary)\n",
    "- Create and rename check images\n",
    "- Create folder of valid training images with corresponding raster mask\n",
    "- Save image data (bounding boxes) to JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN FUNCTIONS #\n",
    "#shapeLocation = work_directory + \"/data/n2000_project/shape/gras_manueel_ahn_2016.shp\"\n",
    "#bounding_boxes_features, areas = dc.getBoundingBoxes(shapeLocation = shapeLocation)\n",
    "#bounding_boxes_images = dc.createImageBoundingBoxes(bounding_boxes_features, areas)\n",
    "#bounding_boxes_images = sample(bounding_boxes_images,1000)\n",
    "#bounding_boxes_images = bounding_boxes_images[:75]\n",
    "#bounding_boxes_images_list = []\n",
    "#shapeLocation = work_directory+\"/data/n2000_project/shape/Gras_bos_handmatig.shp\"\n",
    "#bounding_boxes_images = dc.createImageBoundingBoxes2(shapeLocation = shapeLocation)\n",
    "#bounding_boxes_images = sample(bounding_boxes_images,1000)\n",
    "#bounding_boxes_images_list.append(bounding_boxes_images)\n",
    "\n",
    "#shapeLocation = work_directory + \"/data/n2000_project/shape/gras_manueel_ahn_2016.shp\"\n",
    "#bounding_boxes_images = dc.createImageBoundingBoxes2(shapeLocation = shapeLocation)\n",
    "#bounding_boxes_images = sample(bounding_boxes_images, 700)\n",
    "# bounding_boxes_images_list.append(bounding_boxes_images)\n",
    "\n",
    "# bounding_boxes_images_totaal = []\n",
    "# for i in range(len(bounding_boxes_images_list)):\n",
    "#     for bb in bounding_boxes_images_list[i]:\n",
    "#         bounding_boxes_images_totaal.append(bb)\n",
    "\n",
    "\n",
    "#dc.downloadTrainingImages(bounding_boxes_images, path_rgb_data, name = \"grasManueelAhn256pxRGB\", ir = False, years = ['2016'])\n",
    "#dc2.downloadTrainingImages(bounding_boxes_images, path_cir_data, name = \"grasManueelAhn256pxIR\", ir = True, years = ['2016'])\n",
    "#dc.saveImageDataToJson(image_directory = path_rgb_data, bounding_boxes_images = bounding_boxes_images, file_name = \"grasManueelAhn256px.json\", image_size = (256,256))\n",
    "#mask = work_directory+\"/data/n2000_project/shape/gras_manueel_ahn_2016_clipLayer2.shp\"\n",
    "#dc.createRasterMasks(path_rgb_data, path_mask_data, mask)  \n",
    "\n",
    "# CHECK VARIABLES # CHECK FOLDER\n",
    "\n",
    "#dc.convertMaskToBinaryMask(src_folder = path_mask_data, dst_folder = path_mask_data_binair)\n",
    "#mask = work_directory+\"/data/n2000_project/shape/Gras_bos_handmatig_clipLayer_dissolve.shp\"\n",
    "#dc.createCheckingImages(path_original_data, path_check_images, mask)\n",
    "#dc.createZipfile(path_check_images, filename = \"grasManueel256pxIR_check.gzip\")\n",
    "#dc.createZipfile(path_training_data, filename = \"bgt_Gras_256pxIR.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dc.create4dimensionalImage(path_rgb_data, path_cir_data, path_training_data, name = 'grasManueelAhn256pxRGB.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.createZipfile(path_training_data, filename = \"bgt_Gras_256pxIR.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/bomenspotter'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "zip_name = work_directory + '/notebooks/Bas/Scripts_20190527.zip'\n",
    "directory_name = work_directory + '/notebooks/Bas'\n",
    "\n",
    "# Create 'path\\to\\zip_file.zip'\n",
    "shutil.make_archive(zip_name, 'zip', directory_name)\n",
    "                \n",
    "work_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/bomenspotter'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing \n",
    "- Clean up data\n",
    "- Devide image data in training- validation and test set\n",
    "- Normalize image data\n",
    "- Perform data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN FUNCTIONS # \n",
    "\n",
    "#dp.RenameCheckImages()\n",
    "#dp.PrepareTrainingData()\n",
    "#dp.RemoveInvalidData()\n",
    "#dp.CreateH5_files(\"grasManueelAhn256pxCirRgb.h5\")\n",
    "#x_train, y_train, x_val, y_val, x_test, y_test, filenamesTest = dp.DevideData2(path_dataset = (path_training_data+\"/bgt_Gras_256pxIR.h5\"))\n",
    "#x_train, y_train, x_val, y_val, x_test, y_test, stats =  dp.NormalizeData(x_train, y_train, x_val, y_val, x_test, y_test)\n",
    "\n",
    "# Perform data augmentation to improve + increase training dataset\n",
    "# Create N2000_DataAugmentation object\n",
    "#da = N2000_DataAugmentation(x_train, y_train)\n",
    "#x_train_hf, y_train_hf = da.HorizontalFlip(batch_size = 200)\n",
    "#x_train_vf, y_train_vf = da.VerticalFlip(batch_size = 200)\n",
    "#x_train_rr, y_train_rr = da.RandomRotation(batch_size = 200)\n",
    "\n",
    "# Merge original training data with data augmentation\n",
    "#x_train_total = np.concatenate([x_train,x_train_hf, x_train_vf, x_train_rr])\n",
    "#y_train_total = np.concatenate([y_train,y_train_hf, y_train_vf, y_train_rr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train U-net convolutional neural network for semantic segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/conda-envs/TensorflowBas/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/jovyan/conda-envs/TensorflowBas/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'EarlyStopping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-542b697907d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcheckpoint2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_checkpoints\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/Run1_weights_best_loss.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"min\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtensorboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tensorboard/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# Reduce learning rate on plateu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mreduce_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0000001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EarlyStopping' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize Unet model\n",
    "model = unet(input_size = (256, 256, 3), drop_out = 0.2, lr = 0.00005)\n",
    "\n",
    "# Checkpoints\n",
    "checkpoint = ModelCheckpoint((folder_checkpoints + '/Run1_weights_best.h5'), monitor='val_acc', verbose = 1, save_best_only=True, mode = \"max\", period = 1)\n",
    "checkpoint2 = ModelCheckpoint((folder_checkpoints + '/Run1_weights_best_loss.h5'), monitor='val_loss', verbose = 1, save_best_only=True, mode = \"min\", period = 1)\n",
    "tensorboard = TensorBoard(log_dir='tensorboard/', write_graph=True, write_images=True)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 4)\n",
    "# Reduce learning rate on plateu\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0000001)\n",
    "# CSV Logger\n",
    "csv_logger = CSVLogger(folder_checkpoints + '/Run1_training.csv', append = True, separator = ',')\n",
    "\n",
    "calbacks_list = [checkpoint, checkpoint2, tensorboard, es, reduce_lr]\n",
    "\n",
    "# Model training\n",
    "history =  model.fit(x_train_total, y_train_total, validation_data = (x_val, y_val), batch_size=8, epochs=30, verbose=2, shuffle=True, callbacks=calbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Unet model\n",
    "model = unet(input_size = (256, 256, 3), drop_out = 0.2, lr = 0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(folder_checkpoints + '/Run1_trainHistory', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)\n",
    "# import json\n",
    "# with open('file.json', 'w') as f:\n",
    "#     json.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# evaluate the model\n",
    "_, train_acc = model.evaluate(x_train_total, y_train_total, verbose=0)\n",
    "_, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard --logdir=/full_path_to_your_logs\n",
    "# plot training history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(x_train_total, y_train_total, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOWNLOAD AHN3\n",
    "wms = \"https://geodata.nationaalgeoregister.nl/ahn3/wms\"\n",
    "dsm = 'ahn3_05m_dsm'\n",
    "dtm = 'ahn3_05m_dtm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = pycrs.parse.from_epsg_code(self.epsg).to_proj4()     \n",
    "\n",
    "# Loop trough the bounding box coordinates of training images need to be downloaded\n",
    "for i in range(len(bb_image_patches)):\n",
    "    print(str(i) + \" out of: \" + str(len(bb_image_patches)))\n",
    "    if ir == False:\n",
    "        if '2018' in years:\n",
    "            img_2018 = self.wms.getmap(layers=[dsm], styles=[], srs='EPSG:28992', crs='EPSG:28992', bbox=bb_image_patches[i],  size=self.image_size, format='image/tiff', transparent=True) # stream = True verwijderd  \n",
    "        if '2017' in years:\n",
    "            img_2017 = self.wms.getmap(layers=['2017_ortho25'], styles=[], srs='EPSG:28992', crs='EPSG:28992', bbox=bb_image_patches[i],  size=self.image_size, format='image/tiff', transparent=True)  \n",
    "        if '2016' in years:\n",
    "            img_2016 = self.wms.getmap(layers=['2016_ortho25'], styles=[], srs='EPSG:28992', crs='EPSG:28992', bbox=bb_image_patches[i],  size=self.image_size, format='image/tiff', transparent=True)  \n",
    "    else:\n",
    "        if '2018' in years:\n",
    "            img_2018 = self.wms.getmap(layers=['2018_ortho25IR'], styles=[], srs='EPSG:28992', crs='EPSG:28992', bbox=bb_image_patches[i],  size=self.image_size, format='image/tiff', transparent=True) # stream = True verwijderd  \n",
    "        if '2017' in years:\n",
    "            img_2017 = self.wms.getmap(layers=['2017_ortho25IR'], styles=[], srs='EPSG:28992', crs='EPSG:28992', bbox=bb_image_patches[i],  size=self.image_size, format='image/tiff', transparent=True)  \n",
    "        if '2016' in years: \n",
    "            img_2016 = self.wms.getmap(layers=['2016_ortho25IR'], styles=[], srs='EPSG:28992', crs='EPSG:28992', bbox=bb_image_patches[i],  size=self.image_size, format='image/tiff', transparent=True)  \n",
    "\n",
    "\n",
    "    # Define filenames\n",
    "    filename_2018 = store_path + \"/\" + str(i) + \"_2018_\" + name + \".tif\"  \n",
    "    filename_2017 = store_path + \"/\" + str(i) + \"_2017_\" + name + \".tif\"      \n",
    "    filename_2016 = store_path + \"/\" + str(i) + \"_2016_\" + name + \".tif\"      \n",
    "\n",
    "    # Write images disk (as tiff files with spatial information)\n",
    "    files = []\n",
    "    if '2018' in years:\n",
    "        out = open(filename_2018, 'wb')\n",
    "        out.write(img_2018.read())\n",
    "        out.close()  \n",
    "        files.append(filename_2018)\n",
    "    if '2017' in years:\n",
    "        out = open(filename_2017, 'wb')\n",
    "        out.write(img_2017.read())\n",
    "        out.close()\n",
    "        files.append(filename_2017)\n",
    "    if '2016' in years: \n",
    "        out = open(filename_2016, 'wb')\n",
    "        out.write(img_2016.read())\n",
    "        out.close() \n",
    "        files.append(filename_2016)\n",
    "\n",
    "    # List written files, update projetion and move tile to spatial position\n",
    "    for file in files:\n",
    "        # SET PROJECTION AND MOVE TILE TO POSITION #\n",
    "        dataset = gdal.Open(file,1)\n",
    "\n",
    "        # Get raster projection\n",
    "        srs = osr.SpatialReference()\n",
    "        srs.ImportFromEPSG(self.epsg)\n",
    "        dest_wkt = srs.ExportToWkt()\n",
    "\n",
    "        # Set projection\n",
    "        dataset.SetProjection(dest_wkt)\n",
    "\n",
    "        gt =  dataset.GetGeoTransform()\n",
    "        gtl = list(gt)\n",
    "        gtl[0] = bb_image_patches[i][0]\n",
    "        gtl[1] = self.cell_size\n",
    "        gtl[3] = bb_image_patches[i][3]\n",
    "        gtl[5] = (-1 * self.cell_size)\n",
    "        dataset.SetGeoTransform(tuple(gtl))\n",
    "        dataset = None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/conda-envs/TensorflowBas/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/jovyan/conda-envs/TensorflowBas/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = unet_multiclass(n_classes = 2, input_size = (256, 256, 3), drop_out = 0.2, lr = 0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 64) 36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 128 147584      conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 256)  590080      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 512)  2359808     conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 512)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 512)  0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 1024) 4719616     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 1024) 9438208     conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16, 16, 1024) 0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 1024) 0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 512)  2097664     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 1024) 0           dropout_1[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  524544      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 512)  0           conv2d_6[0][0]                   \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 128 131200      up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 256 0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 128 295040      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 128 147584      conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256, 256, 128 0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 256, 2)  1154        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 256, 256, 2)  6           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 2, 65536)     0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 65536, 2)     0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 65536, 2)     0           permute_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,032,840\n",
      "Trainable params: 31,032,840\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TensorflowBas]",
   "language": "python",
   "name": "conda-env-TensorflowBas-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
