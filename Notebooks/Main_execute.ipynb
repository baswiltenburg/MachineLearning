{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### Run sementic segmentation model U-net with pretrained weights ###\n",
    "import os\n",
    "os.chdir('E:/BasW/Notebooks') \n",
    "work_directory = os.getcwd()\n",
    "os.chdir(work_directory+'/Scripts')\n",
    "from DataCreation import *\n",
    "from DataPreprocessing import *\n",
    "from DataAugmentation import *\n",
    "from DataNormalization import *\n",
    "from Unet import unet\n",
    "import CreateResults as cr\n",
    "import tensorflow\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import backend as keras\n",
    "os.chdir('../..') # --> ensures that work directory = E:/BasW/Notebooks\n",
    "work_directory = \"E:/BasW/Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set variables and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables and path directories\n",
    "image_size = (256, 256) \n",
    "cell_size = 0.25 \n",
    "epsg = 28992    \n",
    "# Create N2000_DataPreparation object\n",
    "dp = N2000_DataPreparation(image_size = image_size)\n",
    "dn = DataNormalization(image_size = (256,256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save testing data as h5 file (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.SaveTrainingData(path_training_data = f\"{work_directory}/Gras/testing/BGT/training_data_CirRgb\", name_file = 'BGT_CirRgb.h5')\n",
    "dp.SaveTrainingData(path_training_data = f\"{work_directory}/Gras/testing/BGT/training_data_Cir\", name_file = 'BGT_Cir.h5')\n",
    "dp.SaveTrainingData(path_training_data = f\"{work_directory}/Gras/testing/BGT/training_data_6channels\", name_file = 'BGT_6Channels.h5')\n",
    "dp.SaveTrainingData(path_training_data = f\"{work_directory}/Gras/testing/BGT/training_data_RgbNirNdviHeight\", name_file = 'BGT_RgbNirNdviHeight.h5')\n",
    "dp.SaveTrainingData(path_training_data = f\"{work_directory}/Gras/testing/Tuinen/training_data_CirRgb\", name_file = 'Tuinen_CirRgb.h5')\n",
    "dp.SaveTrainingData(path_training_data = f\"{work_directory}/Gras/testing/Tuinen/training_data_Cir\", name_file = 'Tuinen_Cir.h5')\n",
    "dp.SaveTrainingData(path_training_data = f\"{work_directory}/Gras/testing/Tuinen/training_data_6channels\", name_file = 'Tuinen_6Channels.h5')\n",
    "dp.SaveTrainingData(path_training_data = f\"{work_directory}/Gras/testing/Tuinen/training_data_RgbNirNdviHeight\", name_file = 'Tuinen_RgbNirNdviHeight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mask_data = f\"{work_directory}/Gras/testing/Tuinen/training_data_CirRgb/mask\"\n",
    "files = os.listdir(path_mask_data)\n",
    "for file in files:\n",
    "    split = file.split(\"_\")\n",
    "    split[2] = \"CirRgb\"\n",
    "    newname = f\"{split[0]}_{split[1]}_{split[2]}_mask.tif\"\n",
    "    os.rename(f\"{path_mask_data}/{file}\", f\"{path_mask_data}/{newname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.SaveTrainingData(path_training_data = f\"{work_directory}/Gras/testing/BGT/training_data_RgbNirNdviHeight\", name_file = 'BGT_RgbNirNdviHeight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the U-net convolutional neural network on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "### Predictions of model X ###\n",
    "json_path = work_directory + \"/Gras/testing/BGT/grasBGTTesting.json\"\n",
    "geotiff_folder = work_directory + \"/Gras/predictions/Run6/BGT\"\n",
    "model_path = work_directory + \"/Gras/checkpoints/JsonModels/gras_run6.json\"\n",
    "model_weights = work_directory + \"/Gras/checkpoints/Run6_weights_best.h5\"\n",
    "\n",
    "# Open saved U-net model from json\n",
    "json_file = open(model_path, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "# Convert Json model to Tensorflow ConvNetmodel\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# Load weights into the model\n",
    "loaded_model.load_weights(model_weights)\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions and write prediction to geotiff\n",
    "h5Path = f\"{work_directory}/Gras/testing/BGT/training_data_CirRgb/BGT_CirRgb.h5\"\n",
    "images, masks, filenames = cr.readH5File(h5Path)\n",
    "x_test = images\n",
    "y_test = masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 256, 256, 1)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119.63\n",
      "124.242\n",
      "118.687\n",
      "135.976\n"
     ]
    }
   ],
   "source": [
    "# Normalize test dataset \n",
    "stats_file = work_directory + \"/Gras/training/Run6/2016_2017_FromVegscan_NormalizationCirRgbPerBand.csv\"\n",
    "x_test = dn.NormalizeDataPerBand(h5_file = h5Path, stats_file=stats_file, mask = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 256, 256, 4) (140, 256, 256, 1)\n",
      "-0.00858499 1.0000709 1.0\n",
      "140\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape, y_test.shape)\n",
    "print(np.min(x_test), np.max(x_test), np.max(y_test))\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.27433628 1.0000529\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-ac34044b5aba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmask_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\BasTensorflow\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2697\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2698\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[1;32m-> 2699\u001b[1;33m         None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2700\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2701\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\BasTensorflow\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1808\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1810\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\BasTensorflow\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5492\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5494\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5495\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\BasTensorflow\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    636\u001b[0m         if not (self._A.ndim == 2\n\u001b[0;32m    637\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m--> 638\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PLOT IMAGE ##\n",
    "train_img = x_test[8]\n",
    "mask_img = y_test[8]\n",
    "print(np.min(train_img), np.max(train_img))\n",
    "plt.imshow(train_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## PLOT MASK ##\n",
    "mask_img = mask_img.reshape(256,256)\n",
    "plt.imshow(mask_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_test)):\n",
    "    j = i+1\n",
    "    image = x_test[i:j]\n",
    "    filename = filenames[i:j][0]\n",
    "    prediction = loaded_model.predict(image, batch_size = 32)\n",
    "    prediction = np.squeeze(prediction, axis = 0)\n",
    "    cr.writeGeoTiff(json_path, prediction, filename, geotiff_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cr.vectorizePrediction(geotiff_folder, cat = 'bgt_gras_prob90', prob_treshold = 0.9)\n",
    "#cr.vectorizePrediction(geotiff_folder, cat = 'bgt_gras_prob75', prob_treshold = 0.75)\n",
    "#cr.vectorizePrediction(geotiff_folder, cat = 'bgt_gras6channels_prob25', prob_treshold = 0.25)\n",
    "cr.vectorizePrediction(geotiff_folder, cat = 'GrasFromVegScanner_prob50', prob_treshold = 0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0_2016_h5130',\n",
       " '100_2016_h5130',\n",
       " '101_2016_h5130',\n",
       " '102_2016_h5130',\n",
       " '103_2016_h5130',\n",
       " '104_2016_h5130',\n",
       " '105_2016_h5130',\n",
       " '106_2016_h5130',\n",
       " '107_2016_h5130',\n",
       " '108_2016_h5130',\n",
       " '109_2016_h5130',\n",
       " '10_2016_h5130',\n",
       " '110_2016_h5130',\n",
       " '111_2016_h5130',\n",
       " '112_2016_h5130',\n",
       " '113_2016_h5130',\n",
       " '114_2016_h5130',\n",
       " '115_2016_h5130',\n",
       " '116_2016_h5130',\n",
       " '117_2016_h5130',\n",
       " '118_2016_h5130',\n",
       " '119_2016_h5130',\n",
       " '11_2016_h5130',\n",
       " '120_2016_h5130',\n",
       " '121_2016_h5130',\n",
       " '122_2016_h5130',\n",
       " '123_2016_h5130',\n",
       " '124_2016_h5130',\n",
       " '125_2016_h5130',\n",
       " '126_2016_h5130',\n",
       " '127_2016_h5130',\n",
       " '128_2016_h5130',\n",
       " '129_2016_h5130',\n",
       " '12_2016_h5130',\n",
       " '130_2016_h5130',\n",
       " '131_2016_h5130',\n",
       " '132_2016_h5130',\n",
       " '133_2016_h5130',\n",
       " '134_2016_h5130',\n",
       " '135_2016_h5130',\n",
       " '136_2016_h5130',\n",
       " '137_2016_h5130',\n",
       " '138_2016_h5130',\n",
       " '139_2016_h5130',\n",
       " '13_2016_h5130',\n",
       " '14_2016_h5130',\n",
       " '15_2016_h5130',\n",
       " '16_2016_h5130',\n",
       " '17_2016_h5130',\n",
       " '18_2016_h5130',\n",
       " '19_2016_h5130',\n",
       " '1_2016_h5130',\n",
       " '20_2016_h5130',\n",
       " '21_2016_h5130',\n",
       " '22_2016_h5130',\n",
       " '23_2016_h5130',\n",
       " '24_2016_h5130',\n",
       " '25_2016_h5130',\n",
       " '26_2016_h5130',\n",
       " '27_2016_h5130',\n",
       " '28_2016_h5130',\n",
       " '29_2016_h5130',\n",
       " '2_2016_h5130',\n",
       " '30_2016_h5130',\n",
       " '31_2016_h5130',\n",
       " '32_2016_h5130',\n",
       " '33_2016_h5130',\n",
       " '34_2016_h5130',\n",
       " '35_2016_h5130',\n",
       " '36_2016_h5130',\n",
       " '37_2016_h5130',\n",
       " '38_2016_h5130',\n",
       " '39_2016_h5130',\n",
       " '3_2016_h5130',\n",
       " '40_2016_h5130',\n",
       " '41_2016_h5130',\n",
       " '42_2016_h5130',\n",
       " '43_2016_h5130',\n",
       " '44_2016_h5130',\n",
       " '45_2016_h5130',\n",
       " '46_2016_h5130',\n",
       " '47_2016_h5130',\n",
       " '48_2016_h5130',\n",
       " '49_2016_h5130',\n",
       " '4_2016_h5130',\n",
       " '50_2016_h5130',\n",
       " '51_2016_h5130',\n",
       " '52_2016_h5130',\n",
       " '53_2016_h5130',\n",
       " '54_2016_h5130',\n",
       " '55_2016_h5130',\n",
       " '56_2016_h5130',\n",
       " '57_2016_h5130',\n",
       " '58_2016_h5130',\n",
       " '59_2016_h5130',\n",
       " '5_2016_h5130',\n",
       " '60_2016_h5130',\n",
       " '61_2016_h5130',\n",
       " '62_2016_h5130',\n",
       " '63_2016_h5130',\n",
       " '64_2016_h5130',\n",
       " '65_2016_h5130',\n",
       " '66_2016_h5130',\n",
       " '67_2016_h5130',\n",
       " '68_2016_h5130',\n",
       " '69_2016_h5130',\n",
       " '6_2016_h5130',\n",
       " '70_2016_h5130',\n",
       " '71_2016_h5130',\n",
       " '72_2016_h5130',\n",
       " '73_2016_h5130',\n",
       " '74_2016_h5130',\n",
       " '75_2016_h5130',\n",
       " '76_2016_h5130',\n",
       " '77_2016_h5130',\n",
       " '78_2016_h5130',\n",
       " '79_2016_h5130',\n",
       " '7_2016_h5130',\n",
       " '80_2016_h5130',\n",
       " '81_2016_h5130',\n",
       " '82_2016_h5130',\n",
       " '83_2016_h5130',\n",
       " '84_2016_h5130',\n",
       " '85_2016_h5130',\n",
       " '86_2016_h5130',\n",
       " '87_2016_h5130',\n",
       " '88_2016_h5130',\n",
       " '89_2016_h5130',\n",
       " '8_2016_h5130',\n",
       " '90_2016_h5130',\n",
       " '91_2016_h5130',\n",
       " '92_2016_h5130',\n",
       " '93_2016_h5130',\n",
       " '94_2016_h5130',\n",
       " '95_2016_h5130',\n",
       " '96_2016_h5130',\n",
       " '97_2016_h5130',\n",
       " '98_2016_h5130',\n",
       " '99_2016_h5130',\n",
       " '9_2016_h5130']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW RESULTS ON TEST SET --> OUD --> NOT GEOTIFF\n",
    "\n",
    "import scipy\n",
    "predictions = loaded_model.predict(x_test, batch_size = 4)\n",
    "predictions = predictions[0:20]\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    pred =  predictions[i].reshape(512,512)\n",
    "    img = x_test[i]\n",
    "    gt = y_test[i].reshape(512,512)\n",
    "\n",
    "    scipy.misc.imsave(geotiff_folder + '/Test_img_' +str(i)+\".tif\", img)\n",
    "    scipy.misc.imsave(geotiff_folder + '/Test_gt_' + str(i)+\".tif\", gt)\n",
    "    scipy.misc.imsave(geotiff_folder + '/Test_prediction_'+str(i)+\".tif\", pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (BasTensorflow)",
   "language": "python",
   "name": "bastensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
