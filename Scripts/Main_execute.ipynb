{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### Run sementic segmentation model U-net with pretrained weights ###\n",
    "import os\n",
    "os.chdir('E:/BasW/Notebooks') \n",
    "work_directory = os.getcwd()\n",
    "os.chdir(work_directory+'/Scripts')\n",
    "from pathlib import Path\n",
    "from DataPreprocessing import *\n",
    "from DataCreation import N2000_Data\n",
    "from Unet import unet\n",
    "import CreateResults as cr\n",
    "import tensorflow\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras import backend as keras\n",
    "os.chdir('../..') # --> ensures that work directory = E:/BasW/Notebooks\n",
    "work_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set variables and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables and path directories\n",
    "image_size = (512, 512) \n",
    "cell_size = 0.25 \n",
    "epsg = 28992    \n",
    "path_training_data = work_directory + \"/Data/testing\"\n",
    "path_mask_data_binair = work_directory \n",
    "path_original_data = work_directory\n",
    "h5Path = work_directory + \"/Data/h5130/testing/H5130_Drenthe.h5\"\n",
    "json_path = work_directory + \"/Data/h5130/testing/H5130_Drenthe.json\"\n",
    "stats_file = work_directory + \"/Data/h5130/NormalizationStatsH5130.csv\"\n",
    "geotiff_folder = work_directory + \"/Data/h5130/predictions\"\n",
    "model_path = work_directory + '/Data/h5130/checkpoints/JsonModels/Run2_H5130.json'\n",
    "model_weights = work_directory + '/Data/h5130/checkpoints/Run2_weights_best.h5'\n",
    "# Create N2000_DataPreparation object\n",
    "dp = N2000_DataPreparation(image_size, path_training_data, path_mask_data_binair, path_original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and normalize test data with training data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.737 25.86 -3.431 6.429\n"
     ]
    }
   ],
   "source": [
    "# Normalize test dataset\n",
    "x_test, y_test = dp.ApplyNormalization(h5Path, stats_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the U-net convolutional neural network on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\envs\\BasTensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Anaconda\\envs\\BasTensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# Open saved U-net model from json\n",
    "json_file = open(model_path, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "# Convert Json model to Tensorflow ConvNetmodel\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# Load weights into the model\n",
    "loaded_model.load_weights(model_weights)\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict images and plot predicted images (code on Azure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 77.15%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loaded_model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "scores = loaded_model.evaluate(x_test, y_test, verbose=0, batch_size = 4) \n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.737 25.86 -3.431 6.429\n",
      "23_2018_H5130\n",
      "61_2018_H5130\n",
      "14_2018_H5130\n",
      "24_2017_H5130\n",
      "4_2018_H5130\n",
      "74_2017_H5130\n",
      "20_2017_H5130\n",
      "70_2017_H5130\n",
      "14_2016_H5130\n",
      "61_2017_H5130\n",
      "0_2018_H5130\n",
      "5_2018_H5130\n",
      "48_2017_H5130\n",
      "70_2016_H5130\n",
      "39_2016_H5130\n",
      "62_2018_H5130\n",
      "40_2018_H5130\n",
      "53_2016_H5130\n",
      "39_2018_H5130\n",
      "62_2016_H5130\n",
      "18_2018_H5130\n",
      "19_2018_H5130\n",
      "36_2017_H5130\n",
      "40_2016_H5130\n",
      "39_2017_H5130\n",
      "32_2018_H5130\n",
      "10_2016_H5130\n",
      "34_2018_H5130\n",
      "31_2017_H5130\n",
      "30_2016_H5130\n",
      "67_2016_H5130\n",
      "72_2017_H5130\n",
      "17_2016_H5130\n",
      "48_2018_H5130\n",
      "0_2017_H5130\n",
      "33_2016_H5130\n",
      "24_2018_H5130\n",
      "21_2017_H5130\n",
      "47_2018_H5130\n",
      "12_2018_H5130\n",
      "36_2018_H5130\n",
      "37_2018_H5130\n",
      "57_2018_H5130\n",
      "20_2016_H5130\n",
      "72_2018_H5130\n",
      "50_2018_H5130\n",
      "51_2018_H5130\n",
      "18_2016_H5130\n",
      "10_2017_H5130\n",
      "46_2018_H5130\n",
      "0_2016_H5130\n",
      "11_2018_H5130\n",
      "28_2018_H5130\n",
      "63_2018_H5130\n",
      "74_2018_H5130\n",
      "11_2016_H5130\n",
      "53_2018_H5130\n",
      "50_2016_H5130\n",
      "46_2016_H5130\n",
      "14_2017_H5130\n",
      "37_2017_H5130\n",
      "21_2018_H5130\n",
      "63_2017_H5130\n",
      "4_2016_H5130\n",
      "17_2018_H5130\n",
      "12_2016_H5130\n",
      "29_2017_H5130\n",
      "49_2017_H5130\n",
      "12_2017_H5130\n",
      "70_2018_H5130\n",
      "32_2016_H5130\n",
      "16_2018_H5130\n",
      "72_2016_H5130\n",
      "62_2017_H5130\n",
      "21_2016_H5130\n",
      "29_2016_H5130\n",
      "49_2018_H5130\n",
      "23_2017_H5130\n",
      "20_2018_H5130\n",
      "73_2016_H5130\n",
      "25_2018_H5130\n",
      "18_2017_H5130\n",
      "37_2016_H5130\n",
      "73_2018_H5130\n",
      "19_2017_H5130\n",
      "19_2016_H5130\n",
      "16_2017_H5130\n",
      "48_2016_H5130\n",
      "63_2016_H5130\n",
      "5_2016_H5130\n",
      "11_2017_H5130\n",
      "16_2016_H5130\n",
      "17_2017_H5130\n",
      "74_2016_H5130\n",
      "51_2017_H5130\n",
      "61_2016_H5130\n",
      "53_2017_H5130\n",
      "50_2017_H5130\n",
      "24_2016_H5130\n",
      "29_2018_H5130\n",
      "4_2017_H5130\n",
      "47_2017_H5130\n",
      "36_2016_H5130\n",
      "31_2018_H5130\n",
      "57_2017_H5130\n",
      "51_2016_H5130\n",
      "25_2017_H5130\n",
      "46_2017_H5130\n",
      "49_2016_H5130\n",
      "31_2016_H5130\n",
      "34_2017_H5130\n",
      "10_2018_H5130\n",
      "47_2016_H5130\n",
      "33_2018_H5130\n",
      "25_2016_H5130\n",
      "73_2017_H5130\n",
      "34_2016_H5130\n",
      "67_2018_H5130\n",
      "32_2017_H5130\n",
      "33_2017_H5130\n",
      "67_2017_H5130\n",
      "23_2016_H5130\n",
      "30_2018_H5130\n",
      "5_2017_H5130\n",
      "40_2017_H5130\n",
      "30_2017_H5130\n",
      "57_2016_H5130\n"
     ]
    }
   ],
   "source": [
    "# Make predictions and write prediction to geotiff\n",
    "images, masks, filenames = cr.readH5File(h5Path)\n",
    "x_test, y_test = dp.ApplyNormalization(h5Path, stats_file)\n",
    "for i in range(len(x_test)):\n",
    "    j = i+1\n",
    "    image = x_test[i:j]\n",
    "    filename = filenames[i:j][0]\n",
    "    prediction = loaded_model.predict(image, batch_size = 4)\n",
    "    prediction = np.squeeze(prediction, axis = 0)\n",
    "    cr.writeGeoTiff(json_path, prediction, filename, geotiff_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr.vectorizePrediction(geotiff_folder, cat = 'h5130_prob90', prob_treshold = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW RESULTS ON TEST SET --> OUD --> NOT GEOTIFF\n",
    "\n",
    "import scipy\n",
    "predictions = loaded_model.predict(x_test, batch_size = 4)\n",
    "predictions = predictions[0:20]\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    pred =  predictions[i].reshape(512,512)\n",
    "    img = x_test[i]\n",
    "    gt = y_test[i].reshape(512,512)\n",
    "\n",
    "    scipy.misc.imsave(geotiff_folder + '/Test_img_' +str(i)+\".tif\", img)\n",
    "    scipy.misc.imsave(geotiff_folder + '/Test_gt_' + str(i)+\".tif\", gt)\n",
    "    scipy.misc.imsave(geotiff_folder + '/Test_prediction_'+str(i)+\".tif\", pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TensorflowBas]",
   "language": "python",
   "name": "conda-env-TensorflowBas-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
